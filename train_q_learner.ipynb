{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.classic import connect_four_v3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the PettingZoo environment\n",
    "\n",
    "This notebook provides smalls chunks of code to get you started with the Connect4 project. You do not have to use this code in you final file, but you can if you wish to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = connect_four_v3.env(render_mode=\"rgb_array\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "Here are some implementations of trivial agents that you should be able to beat ultimately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.play_leftmost import PlayLeftmostLegal\n",
    "from agents.random import RandomPlayer\n",
    "from agents.malynx_deep import MalynxDeep, MalynxWithoutBlunder\n",
    "from agents.q_learner import QLearningAgent\n",
    "from agents.human import HumanPlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the pre-trained Q-table for Q-learning agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "q_learning_agent = QLearningAgent()\n",
    "with open(\"training/agent_q_learner.pkl\", 'rb') as f:\n",
    "    q_learning_agent.q_table = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_agent = RandomPlayer()\n",
    "leftmost_agent = PlayLeftmostLegal()\n",
    "malynx_deep_agent = MalynxDeep()\n",
    "malynx_without_blunder_agent = MalynxWithoutBlunder()\n",
    "human_agent = HumanPlayer(name= \"Human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train the QLearner agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvAgainstPolicy: \n",
    "    def __init__(self, env, policy, first_player=True):\n",
    "        self.policy = policy\n",
    "        self.env = env\n",
    "        self.first_player = first_player\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.env.step(action)\n",
    "        obs, reward, terminated, _, _ = self.env.last()\n",
    "        if terminated: \n",
    "            self.last_step = obs, reward, True, False, {}\n",
    "        else: \n",
    "            action = self.policy.get_action(obs)\n",
    "            self.env.step(action)\n",
    "            obs, reward, terminated, _, _ = self.env.last()\n",
    "            self.last_step = obs, -reward, terminated, False, {}\n",
    "        return self.last_step\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        if not(self.first_player): \n",
    "            obs, _, _, _, _ = self.env.last()\n",
    "            action = self.policy.get_action(obs)\n",
    "            self.env.step(action)\n",
    "\n",
    "        self.last_step = self.env.last()\n",
    "        return self.last_step\n",
    "\n",
    "    def last(self):\n",
    "        return self.last_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_game(agent, opponent, first_player=True):\n",
    "    eval_env = EnvAgainstPolicy(env, opponent, first_player=first_player)\n",
    "    done = False\n",
    "    eval_env.reset()\n",
    "    obs, _, _, _, _ = eval_env.last()\n",
    "    while not done:\n",
    "        # We get the action from the agent\n",
    "        action = agent.get_action(obs, epsilon=0)\n",
    "        if action is None:\n",
    "            # The agent cannot play: draw?\n",
    "            return 0\n",
    "        # print(obs['action_mask'],list(np.where(obs['action_mask'] ==1)[0]), action)\n",
    "        # We move according to the action\n",
    "        eval_env.step(action)\n",
    "        next_obs, reward, done, _, _ = eval_env.last()\n",
    "        # We update the agent's Q-table\n",
    "        agent.update(obs, action, reward, done, next_obs)\n",
    "\n",
    "        if done and reward==1:\n",
    "            # The agent won\n",
    "            return 1\n",
    "        elif done and reward==-1:\n",
    "            # The agent lost\n",
    "            return -1\n",
    "        \n",
    "        obs = next_obs\n",
    "\n",
    "    # The game ended in a draw\n",
    "    return 0\n",
    "\n",
    "def train(agent, opponent, N_episodes=10, N_games=100, first_player=True, alternate_first_player=False):\n",
    "    # We print the evolution of the agent's statistics, and at the end we plot the evolution of the win rate\n",
    "    print(f\"{'Episode':<10} {'Win':<10} {'Loss':<10} {'Draw':<10}\")\n",
    "    win_rate = []\n",
    "    for i in range(N_episodes):\n",
    "        win = 0\n",
    "        loss = 0\n",
    "        draw = 0\n",
    "        for _ in range(N_games):\n",
    "            result = train_one_game(agent, opponent, first_player=first_player)\n",
    "            if result == 1:\n",
    "                win += 1\n",
    "            elif result == -1:\n",
    "                loss += 1\n",
    "            else:\n",
    "                draw += 1\n",
    "        print(f\"{i:<10} {win:<10} {loss:<10} {draw:<10}\")\n",
    "        win_rate.append(win / N_games)\n",
    "\n",
    "        if alternate_first_player:\n",
    "            first_player = not first_player\n",
    "\n",
    "    plt.plot(win_rate)\n",
    "    #calculate equation for trendline\n",
    "    x = np.linspace(0, N_episodes-1, N_episodes)\n",
    "    z = np.polyfit(x, win_rate, 1)\n",
    "    p = np.poly1d(z)\n",
    "    #add trendline to plot\n",
    "    plt.plot(x, p(x))\n",
    "    #legends\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Win rate\")\n",
    "    plt.title(\"Evolution of the win rate for {} against {}\".format(agent.name, opponent.name))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_agent(agent, name):\n",
    "    # Save the agent's Q-table\n",
    "    # We try to optimize the size of the file by removing the useless entries\n",
    "    q_table = {}\n",
    "    for key, value in agent.q_table.items():\n",
    "        if value != 0:\n",
    "            q_table[key] = value\n",
    "    \n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(q_table, f)\n",
    "\n",
    "def load_agent(name):\n",
    "    # Load the agent's Q-table\n",
    "    agent = QLearningAgent()\n",
    "    with open(name, 'rb') as f:\n",
    "        agent.q_table = pickle.load(f)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_against_opponent(set_of_opponents,nb_confrontations):\n",
    "    for i in range(nb_confrontations):\n",
    "        opponent = random.choice(list(set_of_opponents))\n",
    "        print(\"Training against {}\".format(opponent.name))\n",
    "        train(q_learning_agent, opponent, N_episodes=100, N_games=200, first_player=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_agents = {random_agent,leftmost_agent,malynx_deep_agent,malynx_without_blunder_agent}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training against Left Player\n",
      "Episode    Win        Loss       Draw      \n",
      "0          200        0          0         \n",
      "1          200        0          0         \n",
      "2          200        0          0         \n",
      "3          200        0          0         \n",
      "4          200        0          0         \n",
      "5          200        0          0         \n",
      "6          200        0          0         \n",
      "7          200        0          0         \n",
      "8          200        0          0         \n",
      "9          200        0          0         \n",
      "10         200        0          0         \n",
      "11         200        0          0         \n",
      "12         200        0          0         \n",
      "13         200        0          0         \n",
      "14         200        0          0         \n",
      "15         200        0          0         \n",
      "16         200        0          0         \n",
      "17         200        0          0         \n",
      "18         200        0          0         \n",
      "19         200        0          0         \n",
      "20         200        0          0         \n",
      "21         200        0          0         \n",
      "22         200        0          0         \n",
      "23         200        0          0         \n",
      "24         200        0          0         \n",
      "25         200        0          0         \n",
      "26         200        0          0         \n",
      "27         200        0          0         \n",
      "28         200        0          0         \n",
      "29         200        0          0         \n",
      "30         200        0          0         \n",
      "31         200        0          0         \n",
      "32         200        0          0         \n",
      "33         200        0          0         \n",
      "34         200        0          0         \n",
      "35         200        0          0         \n",
      "36         200        0          0         \n",
      "37         200        0          0         \n",
      "38         200        0          0         \n",
      "39         200        0          0         \n",
      "40         200        0          0         \n",
      "41         200        0          0         \n",
      "42         200        0          0         \n",
      "43         200        0          0         \n",
      "44         200        0          0         \n",
      "45         200        0          0         \n",
      "46         200        0          0         \n",
      "47         200        0          0         \n",
      "48         200        0          0         \n",
      "49         200        0          0         \n",
      "50         200        0          0         \n",
      "51         200        0          0         \n",
      "52         200        0          0         \n",
      "53         200        0          0         \n",
      "54         200        0          0         \n",
      "55         200        0          0         \n",
      "56         200        0          0         \n",
      "57         200        0          0         \n",
      "58         200        0          0         \n",
      "59         200        0          0         \n",
      "60         200        0          0         \n",
      "61         200        0          0         \n",
      "62         200        0          0         \n",
      "63         200        0          0         \n",
      "64         200        0          0         \n",
      "65         200        0          0         \n",
      "66         200        0          0         \n",
      "67         200        0          0         \n",
      "68         200        0          0         \n",
      "69         200        0          0         \n",
      "70         200        0          0         \n",
      "71         200        0          0         \n",
      "72         200        0          0         \n",
      "73         200        0          0         \n",
      "74         200        0          0         \n",
      "75         200        0          0         \n",
      "76         200        0          0         \n",
      "77         200        0          0         \n",
      "78         200        0          0         \n",
      "79         200        0          0         \n",
      "80         200        0          0         \n",
      "81         200        0          0         \n",
      "82         200        0          0         \n",
      "83         200        0          0         \n",
      "84         200        0          0         \n",
      "85         200        0          0         \n",
      "86         200        0          0         \n",
      "87         200        0          0         \n",
      "88         200        0          0         \n",
      "89         200        0          0         \n",
      "90         200        0          0         \n",
      "91         200        0          0         \n",
      "92         200        0          0         \n",
      "93         200        0          0         \n",
      "94         200        0          0         \n",
      "95         200        0          0         \n",
      "96         200        0          0         \n",
      "97         200        0          0         \n",
      "98         200        0          0         \n",
      "99         200        0          0         \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEWCAYAAAAtuzN2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgvElEQVR4nO3deZxcVZn/8c+XhEAQQoBEhCQkCIiERcDIpgwZdJSgCCIjIg4QF1BBnBF+iNuPRRlHxhkQUBA0AwFkGUQERARZRQhDMiCraEAwCVsCJBKjrM/8cU7DTdHVXZ307Trp+r5fr3p13XPu8tyl7nPPvaerFBGYmZmVYqV2B2BmZlblxGRmZkVxYjIzs6I4MZmZWVGcmMzMrChOTGZmVpQVLjFJCkkbL+O0O0t6sL9jamG5m0q6S9Jzkg5vcZplXs9l0a5ts6yWZZsOZpJ+IenAdscxWEjaQNJiSUPaHUszkr4paYGkJ/phXmdL+mZ/xNUfaktMkh6R9Ne8c7tep9W1vCYxLHVyj4hfR8SmAxlDdhRwQ0SsERGnNFZKulHSp9oQ16sGetvk4+M9yzGLHrfpMsY0UdLlkhblhHe9pB16meYgSbf0x/KXR0RMiYhz6pq/pA0lvSLp9LqW0c0y27ZtI+JPEbF6RLy8PPPp7bMtaUI+Tw3t43w3AI4AJkbEm1rZVjmWv+Vz8QJJl0pary/LHSh1t5j2yDu363VYzcsr1XjgvnYHMVD6+iFbRsu8TbuLT9JGwG+Ae4ANgfWBy4BrJW237GEuvwHanr05AHgW2FfSKu0OxtgAeDoinurjdIdFxOrAW4CRwEn9HVirejyuI6KWF/AI8J5uylcBFgJbVMpGA38F3piHPw3MBp4BLgfWr4wbwMb5/Y3Apyp1BwG35Pc353H/AiwG9gUmA3Mr42+W57GQdJL7YKXubOB7wM+B54DbgY16WN8P5nkszPPcLJdfD7wM/C3H8ZaG6U5oqD+tsp6fAf6Q5/k9QJXpPgE8QDpZ/BIY3ySuc4Aj8vsxeb6H5uGN8jZeqZtt8whwJHA3sAi4CFi1yTIOIp3UTwKeBr6Z5319Hl4AnA+MzOOfC7yS9/li4KhcvgNwa17f3wKTmyzvddsUWBOYDswHHgW+BqzULL5u5nkucFU35aeTWmbN9vtB5GOum7q3Atfmbfwg8JFK3fuBO4E/A3OAYyt1E/J++iTwJ9KxfBBwC/CdvM//CEypTHMj+bPQwrgb5nk+B/wqH1vn9bCOAh4CPgs8CezTUP/evH6LgO8DN7H057LpsUqT45z02fxb3s+LgYVNYpua5/0c8DBwSEP9UcDjwGPAp1j6/NHKPhha2b7fyMfRc8A1wKhctypwXj62FgJ3AOvS5LPdEN9Sy2moWxP4UY5/HulzNQR4D+mz80qe70UtbqtXj5E8fChwb+V89838fi3gStJn6dn8fmyu+0dgVsN8vwj8rHJ+/w7puH0SOAMYnusmA3OBLwFPAOc2PeaaVSzviyaJKddNA05o2EBX5/e7kk5k2+aVPBW4ueFA7jUxNY5b3TD5/cqk5PcVYFhe7nPAppUd9TSwHTCUdGK9sMn6vIWUAP8hz/eoPO9h3cXZ2wFTif1K0lXNBvkg2S3X7Znnv1mO7WvArU3m/Qngivz+Y6QTzEWVup81bpvK/vsfUsthbdKH/zNNlnEQ8BLw+RzPcGDjvD1WIV143Ayc3Oz4ICXNp4HdSYnyH/Lw6BY/ZNOBnwFrkD7svwc+2Sy+bub3BDC1m/K/z9P2lJRfl5iAN5BOdlPzMrchHdcTK9t7y7yuW5E+xHs1nKym5/kMz8t5kXTRNoSUJB4jX6zw+sTU07i3kU4ew4B3kU7MPSWmnYHnSSesU8nHU64blaffO6/nF/Kyu2Lp8Vil5+O8223bENv7SRdBAnYBlgDb5rrd8n7dHFiNlDyq549W9kE1MT1E+qwPz8P/lusOAa7IyxgCvB0Y0eJnf6nlNNT9FPhBPgbeSPo8HtLk89rKtqoeI6NIF3jnVs53XYlpHeDDeX3WAP4buCzXrUK60NqsMt87gQ/n9yeRGhNr52mvAL5Vifkl4Nt5Pq/7HL46z55WZHlepBPPYtIVRNfr07nuPcBDlXF/AxyQ3/8IOLFStzrpQJ9QOZD7IzHtTDpoV6rUX0C+aso76oeVut2B3zVZ168DF1eGVyJd4Uxu8eB8XX2O/V2V4YuBo/P7X5BPupXlLaGbVhPpQ/tsHucM0oeoaxucA3yxyYH+CPDxyvCJwBlN4j8I+FMvx8NewJ0N868mpi/RcAVFuro+sIUP2RDgBfJJP5cdAtzYh/heIp8QG8rfmvfF+k2mW+qYq5TvC/y6oewHwDFN5nMycFJ+PyEv880Ny5ldGV4tj/OmbrZH03FJJ/+XgNUq9efRc2L6Ia+dmHYkfR677m4cANxWGVekhNwVS4/HKj0f591u217242XAF/L7aeSTYh7emIZzQgv7oJqYvlYZ93O8djH9CVJLf6uejtMmy1xqOZXydUkXA8MrZfuRW+8se2JaQjoXzyNdbI/OdWfTzZ2EXLc18Gxl+HRyw4KU9J8lJRqRLtA3qoy7I/DHSswv0OQir/qq+xnTXhExsvI6K5ffAKwmaXtJE/KK/zTXrU+6FQNARCwmXTmP6efY1gfmRMQrlbJHG5ZT7e2yhJQkm82rGvMrpA/n8sbcbPnjge9KWihpIekKRt0tLyIeIh0sW5OS8ZXAY5I2JV1h3rQMy+/OnOqApHUlXShpnqQ/k05+o3qYfjzwj13rlNfrXUArD2dHkVqqj1bKGvflUvF1Y0GTZa1HOnE8nXsudnXk6e351nhg+4b12Z+UHMjH/g2S5ktaRLqd1bh9GmN+dX9ExJL8ttk+aTbu+sAzlbLulvMqScNJt2/Oz/O6jXSb5mN5lPWr00c6A82tzKKVY7Uvx1ljfFMkzZD0TJ7/7ry2HZeKjdcfo63sg6pmcZ5Luoi6UNJjkk6UtHKr69DEeNIx/Xhl2/2A1HJaHofnc/GYiNg/IuY3jiBpNUk/kPRo/uzeDIys9FA8B/iYJAH/RLoof550Z2Q1YFYl5qtzeZf5EfG33oJsS3fxSD1dLiZdAewHXBkRz+Xqx0g7BQBJbyA1Led1M6u/kDZElzf1IYzHgHGSqttggybLaWVe1ZgFjOvDvKKPy5tDatJXk/7wiLi1yfg3AfuQbi3Oy8MHkm7N3NXHZTfTuA7/msu2jIgRwMdJJ6Rm488htZiq6/SGiPi3Fpa9gHQVP75S1rgve9vGvyKdgBt9BJgREc9H6rnY1ZFn817mNwe4qWF9Vo+Iz+b6H5NueYyLiDVJrVk1zKOvx0UrHgfWllT93IzrYfwPASOA70t6IndNHkM6frrmN7Zr5Hzsj61M39djtarH9c+dMH5Cui25bkSMBK7ite24VGy8fj1b2Qe9BxnxYkQcFxETgZ2AD5Bakr2uQw/mkFpMoyrbbUQPx11/HitHAJsC2+fP7t/lcgFExAxSy2dn0gXKubl+AenZ1+aVmNeM1NmiT3G28/+Yfky63bF/ft/lAmCqpK3zgfevwO0R8Ug387gL2Dtn+I1JD4urngTe3GT5t5Oueo6StLKkycAewIXLsC4XA++X9O58pXQE6aBq5cPXW5zdOQP4sqTNASStKam7k2qXm4DDSFc+kJr0h5Ga/svVHbYHa5Bu5S6SNAb4fw31jet8HrCHpPdJGiJpVUmTJY2lF5ULnRMkrSFpPOmB7Hl9iPc4YCdJJ0haO8/n86RnRP+/l2mV4331RWqZvkXSP+Xja2VJ75C0WZ5mDVLL5W+519/Hms69H0XEo8BM4FhJwyTtSDrumzmQdEtsS1Kre2vgncDbJG1J6hy0paS9ci+rQ1n6ArGvx2rVk8BYScOa1A8j3UKaD7wkaQqpI0aXi0nnks1yIv56w/T9sg8k/b2kLXOL4s+ki6SuOzGtfrZXaTh+niR1sPgPSSMkrSRpI0m7NJm+t23VF2uQEsxCSWsDx3QzznTgNODFiLgFXr1TdBZwkqQ3AkgaI+l9fQ2g7sR0hZb+P6au23VExO2kFs/6pPvQXeW/Ih1APyFd8WwEfLTJ/E8iZe4nSc3L8xvqjwXOyc3Kj1QrIuIF0gdyCinTf5/0nOt3fV3JiHiQ1CI4Nc9rD1JX+RdanMV3gX0kPSup1//JiYifkh4gXpib2vfm9WjmJtLB1pWYbiG1NG9uOsXyO47UgWUR6eR1aUP9t4Cv5X1zZETMIT0o/wrpRDOHlMxaPUY/TzqeHiat349JJ9SWRMQfSLcO30Z6/rWQ1AvrQ/mY7MlOpA9y4+u9pGP3MdJtoK6HvpCeURwv6TlS4ru41Vj7wf6ke/9dPSgvIl1ILSVfULyb1GnlicprFukWzYERsYDU0jwxz28iKfE9D8t0rFZdT+rp+oSkBY2V+S7L4aRt9ywpsVxeqf8FcArp0cFsYEau6lrX/toHbwIuISWlB0ift65WRKuf7cUsfezsSmp1DQPuz+t3Cc1vbfe4rfroZFIHjwWkbXZ1N+OcC2zB6y/+vkTe1nl//4rU+uqTrl46ZlaRW2ozSJ0VftTueOok6SJSx57uroz7Oq+VSM+Y9o+IG5Y7uH6UW6v3AqtExEvtjmdFlp89PkXqAfmH/p7/CveVRGYDISLmkq7s15PU8sP4FUG+pbhRvj20G6mletlyzO99kkbmW+9fIT2LmNHLZANC0ockrSJpLVLL7QonpX7xWeCOOpISpP8rMLNuRMQ9pG+CGGzeRLq1ug6pdfPZiLhzOea3I+nWaddtp70i4q/LHWX/OITUFfpl0i22z7U1mkFA0iOki4+9aluGb+WZmVlJfCvPzMyKMmhu5Y0aNSomTJjQ7jDMzFYos2bNWhARo3sfc+AMmsQ0YcIEZs6c2e4wzMxWKJIe7X2sgeVbeWZmVhQnJjMzK4oTk5mZFcWJyczMiuLEZGZmRXFiMjOzojgxmZlZUZyYzMysKE5MZmZWFCcmMzMrihOTmZkVxYnJzMyK4sRkZmZFcWIyM7OiODGZmVlRnJjMzKwoTkxmZlYUJyYzMyuKE5OZmRXFicnMzIrixGRmZkVxYjIzs6I4MZmZWVGcmMzMrChOTGZmVpTaEpOkaZKeknRvk3pJOkXSbEl3S9q2oX6EpLmSTqsrRjMzK0+dLaazgd16qJ8CbJJfBwOnN9R/A7i5lsjMzKxYtSWmiLgZeKaHUfYEpkcyAxgpaT0ASW8H1gWuqSs+MzMrUzufMY0B5lSG5wJjJK0E/AdwZG8zkHSwpJmSZs6fP7+mMM3MbCCV2Pnhc8BVETG3txEj4syImBQRk0aPHj0AoZmZWd2GtnHZ84BxleGxuWxHYGdJnwNWB4ZJWhwRR7chRjMzG2DtTEyXA4dJuhDYHlgUEY8D+3eNIOkgYJKTkplZ56gtMUm6AJgMjJI0FzgGWBkgIs4ArgJ2B2YDS4CpdcViZmYrjtoSU0Ts10t9AIf2Ms7ZpG7nZmbWIUrs/GBmZh3MicnMzIrixGRmZkVxYjIzs6I4MZmZWVGcmMzMrChOTGZmVhQnJjMzK4oTk5mZFcWJyczMiuLEZGZmRXFiMjOzojgxmZlZUZyYzMysKE5MZmZWFCcmMzMrihOTmZkVxYnJzMyK4sRkZmZFcWIyM7OiODGZmVlRnJjMzKwoTkxmZlYUJyYzMyuKE5OZmRXFicnMzIrixGRmZkVxYjIzs6I4MZmZWVGcmMzMrCi1JSZJ0yQ9JeneJvWSdIqk2ZLulrRtLt9a0m2S7svl+9YVo5mZlafOFtPZwG491E8BNsmvg4HTc/kS4ICI2DxPf7KkkfWFaWZmJRla14wj4mZJE3oYZU9gekQEMEPSSEnrRcTvK/N4TNJTwGhgYV2xmplZOdr5jGkMMKcyPDeXvUrSdsAw4KEBjMvMzNqo2M4PktYDzgWmRsQrTcY5WNJMSTPnz58/sAGamVkt2pmY5gHjKsNjcxmSRgA/B74aETOazSAizoyISRExafTo0bUGa2ZmA6Odiely4IDcO28HYFFEPC5pGPBT0vOnS9oYn5mZtUFtnR8kXQBMBkZJmgscA6wMEBFnAFcBuwOzST3xpuZJPwL8HbCOpINy2UERcVddsZqZWTnq7JW3Xy/1ARzaTfl5wHl1xWVmZmUrtvODmZl1JicmMzMrihOTmZkVxYnJzMyK4sRkZmZFcWIyM7OiODGZmVlRnJjMzKwoTkxmZlYUJyYzMyuKE5OZmRXFicnMzIrixGRmZkVxYjIzs6I4MZmZWVF6TUySVpP0dUln5eFNJH2g/tDMzKwTtdJi+i/geWDHPDwP+GZtEZmZWUdrJTFtFBEnAi8CRMQSQLVGZWZmHauVxPSCpOFAAEjaiNSCMjMz63dDWxjnWOBqYJyk84F3AlPrDMrMzDpXr4kpIq6RNAvYgXQL7wsRsaD2yMzMrCO10ivvuoh4OiJ+HhFXRsQCSdcNRHBmZtZ5mraYJK0KrAaMkrQWr3V4GAGMGYDYzMysA/V0K+8Q4J+B9YFZvJaY/gycVm9YZmbWqZompoj4LvBdSZ+PiFMHMCYzM+tgrXR+OFXSFsBEYNVK+fQ6AzMzs87Ua2KSdAwwmZSYrgKmALcATkxmZtbvWvkH232AdwNPRMRU4G3AmrVGZWZmHauVxPTXiHgFeEnSCOApYFy9YZmZWadq5ZsfZkoaCZxF6p23GLitzqDMzKxz9ZiYJAn4VkQsBM6QdDUwIiLuHojgzMys8/R4Ky8igtThoWv4kVaTkqRpkp6SdG+Tekk6RdJsSXdL2rZSd6CkP+TXgS2ui5mZDQKtPGP6X0nvWIZ5nw3s1kP9FGCT/DoYOB1A0trAMcD2wHbAMfmbJ8zMrAO08oxpe2B/SY8CfyF9A0RExFY9TRQRN0ua0MMoewLTc6tshqSRktYjdU2/NiKeAZB0LSnBXdBCrMtkxvc/zRoLH6hr9mZmtXpu5Gbs8Lmz2h1Gv2klMb2vpmWPAeZUhufmsmblryPpYFJriw022KCeKM3MbEC18s0Pjw5EIMsiIs4EzgSYNGlSLOt8BtOVhpnZiq6VZ0x1mcfS/w81Npc1Kzczsw7QzsR0OXBA7p23A7AoIh4Hfgm8V9JaudPDe3OZmZl1gFaeMS0TSReQOjKMkjSX1NNuZYCIOIPUDX13YDawhPxz7RHxjKRvAHfkWR3f1RHCzMwGv1a+xHVv4NvAG0k98rp65Y3oabqI2K+X+gAObVI3DZjWW2xmZjb4tNJiOhHYIyLcn9rMzGrXyjOmJ52UzMxsoLT6Ja4XAZcBz3cVRsSldQVlZmadq5XENILUOeG9lbIAnJjMzKzftfIPtlMHIhAzMzPoITFJOioiTpR0KqmFtJSIOLzWyMzMrCP11GLq6vAwcyACMTMzg54T00aStgPOj4iXBiogMzPrbD0lprHAycBbJd0D/Aa4FbjV38RgZmZ1aZqYIuJIAEnDgEnATqSvDTpT0sKImDgwIZqZWSdppbv4cFKX8TXz6zHgnjqDMjOzztVTr7wzgc2B54DbSbfx/jMinh2g2MzMrAP19JVEGwCrAE+Qfg9pLrBwAGIyM7MO1tMzpt0kidRq2gk4AthC0jPAbRFxzADFaGZmHaTHZ0z5pynulbQQWJRfHwC2I/2+kpmZWb/q6RnT4aSW0k7Ai+Su4qTfSXLnBzMzq0VPLaYJwH8D/5J/8tzMzKx2PT1j+uJABmJmZgat/VCgmZnZgHFiMjOzojgxmZlZUZyYzMysKE5MZmZWFCcmMzMrihOTmZkVxYnJzMyK4sRkZmZFcWIyM7OiODGZmVlRnJjMzKwotSYmSbtJelDSbElHd1M/XtJ1ku6WdKOksZW6EyXdJ+kBSafkHy00M7NBrrbEJGkI8D1gCjAR2E/SxIbRvgNMj4itgOOBb+VpdwLeCWwFbAG8A9ilrljNzKwcdbaYtgNmR8TDEfECcCGwZ8M4E4Hr8/sbKvUBrAoMA1YBVgaerDFWMzMrRJ2JaQwwpzI8N5dV/RbYO7//ELCGpHUi4jZSono8v34ZEQ/UGKuZmRWi3Z0fjgR2kXQn6VbdPOBlSRsDmwFjSclsV0k7N04s6WBJMyXNnD9//kDGbWZmNakzMc0DxlWGx+ayV0XEYxGxd0RsA3w1ly0ktZ5mRMTiiFgM/ALYsXEBEXFmREyKiEmjR4+uaTXMzGwg1ZmY7gA2kbShpGHAR4HLqyNIGiWpK4YvA9Py+z+RWlJDJa1Mak35Vp6ZWQeoLTFFxEvAYcAvSUnl4oi4T9Lxkj6YR5sMPCjp98C6wAm5/BLgIeAe0nOo30bEFXXFamZm5VBEtDuGfjFp0qSYOXNmu8MwM1uhSJoVEZPaHUdVuzs/mJmZLcWJyczMiuLEZGZmRXFiMjOzojgxmZlZUZyYzMysKE5MZmZWFCcmMzMrihOTmZkVxYnJzMyK4sRkZmZFcWIyM7OiODGZmVlRnJjMzKwoTkxmZlYUJyYzMyuKE5OZmRXFicnMzIrixGRmZkVxYjIzs6I4MZmZWVGcmMzMrChOTGZmVhQnJjMzK4oTk5mZFcWJyczMiuLEZGZmRXFiMjOzojgxmZlZUZyYzMysKE5MZmZWlFoTk6TdJD0oabako7upHy/pOkl3S7pR0thK3QaSrpH0gKT7JU2oM1YzMytDbYlJ0hDge8AUYCKwn6SJDaN9B5geEVsBxwPfqtRNB/49IjYDtgOeqitWMzMrR50tpu2A2RHxcES8AFwI7NkwzkTg+vz+hq76nMCGRsS1ABGxOCKW1BirmZkVos7ENAaYUxmem8uqfgvsnd9/CFhD0jrAW4CFki6VdKekf88tsKVIOljSTEkz58+fX8MqmJnZQGt354cjgV0k3QnsAswDXgaGAjvn+ncAbwYOapw4Is6MiEkRMWn06NEDFrSZmdWnzsQ0DxhXGR6by14VEY9FxN4RsQ3w1Vy2kNS6uivfBnwJuAzYtsZYzcysEHUmpjuATSRtKGkY8FHg8uoIkkZJ6orhy8C0yrQjJXU1g3YF7q8xVjMzK0RtiSm3dA4Dfgk8AFwcEfdJOl7SB/Nok4EHJf0eWBc4IU/7Muk23nWS7gEEnFVXrGZmVg5FRLtj6BeTJk2KmTNntjsMM7MViqRZETGp3XFUtbvzg5mZ2VKcmMzMrChOTGZmVhQnJjMzK4oTk5mZFcWJyczMiuLEZGZmRXFiMjOzojgxmZlZUZyYzMysKE5MZmZWFCcmMzMrihOTmZkVxYnJzMyK4sRkZmZFcWIyM7OiODGZmVlRnJjMzKwoTkxmZlYUJyYzMyuKE5OZmRXFicnMzIrixGRmZkVxYjIzs6IoItodQ7+QNB94dDlmMQpY0E/hrCg6cZ2hM9e7E9cZOnO9+7rO4yNidF3BLItBk5iWl6SZETGp3XEMpE5cZ+jM9e7EdYbOXO/BsM6+lWdmZkVxYjIzs6I4Mb3mzHYH0AaduM7QmevdiesMnbneK/w6+xmTmZkVxS0mMzMrihOTmZkVpeMTk6TdJD0oabako9sdT10kjZN0g6T7Jd0n6Qu5fG1J10r6Q/67Vrtj7W+Shki6U9KVeXhDSbfnfX6RpGHtjrG/SRop6RJJv5P0gKQdB/u+lvQv+di+V9IFklYdjPta0jRJT0m6t1LW7b5Vckpe/7slbdu+yFvX0YlJ0hDge8AUYCKwn6SJ7Y2qNi8BR0TERGAH4NC8rkcD10XEJsB1eXiw+QLwQGX428BJEbEx8CzwybZEVa/vAldHxFuBt5HWf9Dua0ljgMOBSRGxBTAE+CiDc1+fDezWUNZs304BNsmvg4HTByjG5dLRiQnYDpgdEQ9HxAvAhcCebY6pFhHxeET8b37/HOlENYa0vufk0c4B9mpLgDWRNBZ4P/DDPCxgV+CSPMpgXOc1gb8DfgQQES9ExEIG+b4GhgLDJQ0FVgMeZxDu64i4GXimobjZvt0TmB7JDGCkpPUGJNDl0OmJaQwwpzI8N5cNapImANsAtwPrRsTjueoJYN12xVWTk4GjgFfy8DrAwoh4KQ8Pxn2+ITAf+K98C/OHkt7AIN7XETEP+A7wJ1JCWgTMYvDv6y7N9u0KeY7r9MTUcSStDvwE+OeI+HO1LtL/Dgya/x+Q9AHgqYiY1e5YBthQYFvg9IjYBvgLDbftBuG+XovUOtgQWB94A6+/3dURBsO+7fTENA8YVxkem8sGJUkrk5LS+RFxaS5+sqtpn/8+1a74avBO4IOSHiHdpt2V9OxlZL7dA4Nzn88F5kbE7Xn4ElKiGsz7+j3AHyNifkS8CFxK2v+DfV93abZvV8hzXKcnpjuATXLPnWGkh6WXtzmmWuRnKz8CHoiI/6xUXQ4cmN8fCPxsoGOrS0R8OSLGRsQE0r69PiL2B24A9smjDap1BoiIJ4A5kjbNRe8G7mcQ72vSLbwdJK2Wj/WudR7U+7qi2b69HDgg987bAVhUueVXrI7/5gdJu5OeQwwBpkXECe2NqB6S3gX8GriH1563fIX0nOliYAPSz4Z8JCIaH6yu8CRNBo6MiA9IejOpBbU2cCfw8Yh4vo3h9TtJW5M6fAwDHgamki5EB+2+lnQcsC+pB+qdwKdIz1MG1b6WdAEwmfTzFk8CxwCX0c2+zUn6NNJtzSXA1IiY2Yaw+6TjE5OZmZWl02/lmZlZYZyYzMysKE5MZmZWFCcmMzMrihOTmZkVxYnJrAlJL0u6q/Lq8UtPJX1G0gH9sNxHJI1a3vmYrajcXdysCUmLI2L1Niz3EdK3ZC8Y6GWblcAtJrM+yi2aEyXdI+l/JG2cy4+VdGR+f3j+7au7JV2Yy9aWdFkumyFpq1y+jqRr8m8J/RBQZVkfz8u4S9IP8k+1mA1qTkxmzQ1vuJW3b6VuUURsSfqv+pO7mfZoYJuI2Ar4TC47Drgzl30FmJ7LjwFuiYjNgZ+S/nsfSZuRvsngnRGxNfAysH9/rqBZiYb2PopZx/prTgjduaDy96Ru6u8Gzpd0GenrYgDeBXwYICKuzy2lEaTfTto7l/9c0rN5/HcDbwfuSN8sw3AG1xevmnXLicls2UST913eT0o4ewBflbTlMixDwDkR8eVlmNZsheVbeWbLZt/K39uqFZJWAsZFxA3Al4A1gdVJX6K7fx5nMrAg/ybWzcDHcvkUYK08q+uAfSS9MdetLWl8fatkVga3mMyaGy7prsrw1RHR1WV8LUl3A88D+zVMNwQ4L//EuYBTImKhpGOBaXm6Jbz2MwXHARdIug+4lfQTDkTE/ZK+BlyTk92LwKGkb482G7TcXdysj9yd26xevpVnZmZFcYvJzMyK4haTmZkVxYnJzMyK4sRkZmZFcWIyM7OiODGZmVlR/g/VuUxsOiIWMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training against Malynx Avoiding Blunder\n",
      "Episode    Win        Loss       Draw      \n",
      "0          0          200        0         \n",
      "1          0          200        0         \n",
      "2          0          200        0         \n",
      "3          0          200        0         \n",
      "4          0          199        1         \n",
      "5          0          200        0         \n",
      "6          1          199        0         \n",
      "7          0          200        0         \n",
      "8          2          198        0         \n",
      "9          1          199        0         \n",
      "10         2          198        0         \n",
      "11         3          197        0         \n",
      "12         76         123        1         \n",
      "13         198        2          0         \n",
      "14         200        0          0         \n",
      "15         200        0          0         \n",
      "16         200        0          0         \n",
      "17         200        0          0         \n",
      "18         200        0          0         \n",
      "19         200        0          0         \n",
      "20         200        0          0         \n",
      "21         200        0          0         \n",
      "22         200        0          0         \n",
      "23         200        0          0         \n",
      "24         200        0          0         \n",
      "25         200        0          0         \n",
      "26         200        0          0         \n",
      "27         200        0          0         \n",
      "28         200        0          0         \n",
      "29         200        0          0         \n",
      "30         200        0          0         \n",
      "31         200        0          0         \n",
      "32         200        0          0         \n",
      "33         200        0          0         \n",
      "34         200        0          0         \n",
      "35         200        0          0         \n",
      "36         200        0          0         \n",
      "37         200        0          0         \n",
      "38         200        0          0         \n",
      "39         200        0          0         \n",
      "40         200        0          0         \n",
      "41         200        0          0         \n",
      "42         200        0          0         \n",
      "43         200        0          0         \n",
      "44         200        0          0         \n",
      "45         200        0          0         \n"
     ]
    }
   ],
   "source": [
    "train_against_opponent(set_agents,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training against Malynx Deep\n",
      "Episode    Win        Loss       Draw      \n",
      "0          0          100        0         \n",
      "1          0          100        0         \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-40ae2bc82816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_against_opponent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmalynx_deep_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-f9315d00d496>\u001b[0m in \u001b[0;36mtrain_against_opponent\u001b[1;34m(opponent)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_against_opponent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training against {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopponent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_learning_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_games\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_player\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_learning_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_games\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_player\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_learning_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_learning_agent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_games\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_player\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-448b061a3b10>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(agent, opponent, N_episodes, N_games, first_player, alternate_first_player)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_games\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_player\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_player\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mwin\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-448b061a3b10>\u001b[0m in \u001b[0;36mtrain_one_game\u001b[1;34m(agent, opponent, first_player)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# print(obs['action_mask'],list(np.where(obs['action_mask'] ==1)[0]), action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# We move according to the action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0meval_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mnext_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# We update the agent's Q-table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-879eb7b0f2f1>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\faust\\Documents\\CS\\3A\\Module 3\\RL\\Projet\\Puissance_Quatre_RL\\agents\\malynx_deep.py\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, obs_mask, epsilon)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegal\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"action_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlegal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                 \u001b[0mmove_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_move_score_depth_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_percentage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmove_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbest_move_score\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                     \u001b[0mbest_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\faust\\Documents\\CS\\3A\\Module 3\\RL\\Projet\\Puissance_Quatre_RL\\agents\\malynx_deep.py\u001b[0m in \u001b[0;36mget_move_score_depth_2\u001b[1;34m(board, i, random_percentage)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mrandom_percentage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_move_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbest_score_for_opponent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMalynxWithoutBlunder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\faust\\Documents\\CS\\3A\\Module 3\\RL\\Projet\\Puissance_Quatre_RL\\agents\\malynx_deep.py\u001b[0m in \u001b[0;36mbest_score_for_opponent\u001b[1;34m(board, i)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mboard_after_i_for_opponent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mmove_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_move_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard_after_i_for_opponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmove_score\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmove_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\faust\\Documents\\CS\\3A\\Module 3\\RL\\Projet\\Puissance_Quatre_RL\\agents\\malynx_deep.py\u001b[0m in \u001b[0;36mget_move_score\u001b[1;34m(board, i)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_move_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mboard_after_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard_after_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\faust\\Documents\\CS\\3A\\Module 3\\RL\\Projet\\Puissance_Quatre_RL\\agents\\malynx_deep.py\u001b[0m in \u001b[0;36mnew_move\u001b[1;34m(board, i)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on est tout en haut y a pas de place\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mnew_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mnew_board\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_board\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_against_opponent(malynx_deep_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's save our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_agent(q_learning_agent, \"training/agent_q_learner_1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
