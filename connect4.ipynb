{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8905775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.classic import connect_four_v3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a72dc",
   "metadata": {},
   "source": [
    "# Using the PettingZoo environment\n",
    "\n",
    "This notebook provides smalls chunks of code to get you started with the Connect4 project. You do not have to use this code in you final file, but you can if you wish to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913932ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = connect_four_v3.env(render_mode=\"rgb_array\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7b137",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "Here are some implementations of trivial agents that you should be able to beat ultimately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d39518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.play_leftmost import PlayLeftmostLegal\n",
    "from agents.random import RandomPlayer\n",
    "from agents.malynx_deep import MalynxDeep, MalynxWithoutBlunder\n",
    "from agents.q_learner import QLearningAgent\n",
    "from agents.human import HumanPlayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70d63c8f",
   "metadata": {},
   "source": [
    "We import the pre-trained Q-table for Q-learning agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337f20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "q_learning_agent = QLearningAgent()\n",
    "with open(\"training/agent_q_learner.pkl\", 'rb') as f:\n",
    "    q_learning_agent.q_table = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04094490",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_agent = RandomPlayer()\n",
    "leftmost_agent = PlayLeftmostLegal()\n",
    "malynx_deep_agent = MalynxDeep()\n",
    "malynx_without_blunder_agent = MalynxWithoutBlunder()\n",
    "human_agent = HumanPlayer(name= \"Human\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c23aef",
   "metadata": {},
   "source": [
    "# Let's play!\n",
    "\n",
    "\n",
    "The following function runs a full game between the two agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf14f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env, agent0, agent1, display=False):\n",
    "    done = False\n",
    "    env.reset()\n",
    "    obs, _, _, _, _ = env.last()\n",
    "    while not done:\n",
    "        for i, agent in enumerate([agent0, agent1]):\n",
    "            action = agent.get_action(obs, epsilon=0)\n",
    "            env.step(action)\n",
    "            if display:\n",
    "                clear_output(wait=True)\n",
    "                plt.imshow(env.render())\n",
    "                plt.show()\n",
    "            obs, reward, terminated, _, _ = env.last()\n",
    "            done = terminated\n",
    "            if np.sum(obs[\"action_mask\"]) == 0:\n",
    "                if display: \n",
    "                    print('Draw')\n",
    "                return 0.5\n",
    "            if done:\n",
    "                if display:\n",
    "                    print(f\"Player {i}: {agent.name} won\")\n",
    "                    print(obs['observation'][:, :, 0]- obs['observation'][:, :, 1])\n",
    "                    print(obs['action_mask'])\n",
    "                return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb13a6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing against Random Player\n",
      "Q-Learning Agent won\n",
      "Playing against Left Player\n",
      "Q-Learning Agent won\n",
      "Playing against Malynx Deep\n",
      "Opponent won\n",
      "Playing against Malynx Avoiding Blunder\n",
      "Opponent won\n"
     ]
    }
   ],
   "source": [
    "for opponent in [random_agent, leftmost_agent, malynx_deep_agent, malynx_without_blunder_agent]:\n",
    "    print(f\"Playing against {opponent.name}\")\n",
    "    game = play_game(env, q_learning_agent, opponent, display=False)\n",
    "    if game == 0:\n",
    "        print(\"Q-Learning Agent won\")\n",
    "    elif game == 1:\n",
    "        print(\"Opponent won\")\n",
    "    else:\n",
    "        print(\"Draw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_game(env, HumanPlayer(), agent, display=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
